# Mongodb NLP

The purpose of this project is to demonstrate how a company can use Natural Language Processing on top of a modern data stack to improve its decision-making quality.  

#### Skills and Expertise:

* Building scalable ETL pipelines for high-performance data processing.
* Designing and implementing data lake/warehouse solutions using Delta Lake concepts.
* Proficiency in programming with Python using frameworks like Spark and Pandas.
* Knowledge of orchestration tools like Airflow, Luiji, Azkaban, Cask
* Familiarity with AWS services, including S3, Kinesis, EMR, Lambda, Athena, Glue, IAM, and RDS.
* Understanding storage formats such as Parquet, JSON, Avro, and Arrow.
* Experience with streaming data processing frameworks like Kafka, KSQL, and Spark Streaming.
* Working knowledge of databases, including MongoDB and Redshift.
* Understanding of storage format differences and schema designs.
* Knowledge of building machine learning pipelines using tools like SparkML, Tensorflow, Scikit-Learn, etc.



#### Architecture
------------------

![image](https://github.com/LNshuti/govgpt/assets/13305262/84a5db54-5385-4a23-9951-e916e6a25bc3)

